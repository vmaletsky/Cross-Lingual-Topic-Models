{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import fasttext\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import io\n",
    "import networkx as nx\n",
    "\n",
    "lang1 = 'en'\n",
    "lang2 = 'uk'\n",
    "langs =[lang1,lang2]\n",
    "pathVectors = 'vectors/'\n",
    "pathAlignment = 'pathAlignment/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for l in langs:\n",
    "    print(l)\n",
    "    !wget -P vectors/ {'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.%s.zip' % l}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0f7c2853ea31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlangs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wiki.multi.%s.vec'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m\"\"\"Load a model given a filepath and return a model object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0meprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/fasttext/FastText.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, args)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfasttext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: wiki.multi.en.vec has wrong file format!"
     ],
     "ename": "ValueError",
     "evalue": "wiki.multi.en.vec has wrong file format!",
     "output_type": "error"
    }
   ],
   "source": [
    "model = {}\n",
    "for lang in langs:\n",
    "    \n",
    "    model[lang] = fasttext.load_model('wiki.%s.vec' % (lang))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for l in langs:\n",
    "    !unzip {'%s/wiki.%s.zip' % (pathVectors, l)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-ae0404c1c826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"кіт\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sentence_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "a = model['uk'].get_sentence_vector(\"кіт\")\n",
    "b = model['en'].get_sentence_vector(\"cat\")\n",
    "\n",
    "distance.cosine(a, b)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def apply_transform(vec, transform):\n",
    "        \"\"\"\n",
    "        Apply the given transformation to the vector space\n",
    "\n",
    "        Right-multiplies given transform with embeddings E:\n",
    "            E = E * transform\n",
    "\n",
    "        Transform can either be a string with a filename to a\n",
    "        text file containing a ndarray (compat. with np.loadtxt)\n",
    "        or a numpy ndarray.\n",
    "        \"\"\"\n",
    "        transmat = np.loadtxt(transform) if isinstance(transform, str) else transform\n",
    "        return np.matmul(vec, transmat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# Align second language\n",
    "aAligned = apply_transform(a,'%sapply_in_%s_to_%s.txt' % (pathAlignment,'uk','en') )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5366788424882428"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 52
    }
   ],
   "source": [
    "distance.cosine(aAligned, b)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9677601978182793"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 53
    }
   ],
   "source": [
    "a = model['uk'].get_word_vector(\"привіт\")\n",
    "b = model['en'].get_word_vector(\"hello\")\n",
    "distance.cosine(a, b)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5312663719018984"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 54
    }
   ],
   "source": [
    "aAligned = apply_transform(a,'%sapply_in_%s_to_%s.txt' % (pathAlignment,'uk','en') )\n",
    "\n",
    "distance.cosine(aAligned, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "0.402226984500885"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 55
    }
   ],
   "source": [
    "a = model['en'].get_word_vector(\"hi\")\n",
    "b = model['en'].get_word_vector(\"hello\")\n",
    "distance.cosine(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_vec(emb_path, nmax=50000):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        next(f)\n",
    "        for i, line in enumerate(f):\n",
    "            word, vect = line.rstrip().split(' ', 1)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "            assert word not in word2id, 'word found twice'\n",
    "            vectors.append(vect)\n",
    "            word2id[word] = len(word2id)\n",
    "            if len(word2id) == nmax:\n",
    "                break\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors)\n",
    "    return embeddings, id2word, word2id\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "nmax = 1000000\n",
    "src_embeddings_en, src_id2word_en, src_word2id_en = load_vec(\"wiki.multi.en.vec\", nmax)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "src_embeddings_uk, src_id2word_uk, src_word2id_uk = load_vec(\"wiki.multi.uk.vec\", nmax)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_nn(word, src_emb, src_id2word, tgt_emb, tgt_id2word, K=5):\n",
    "    print(\"Nearest neighbors of \\\"%s\\\":\" % word)\n",
    "    word2id = {v: k for k, v in src_id2word.items()}\n",
    "    word_emb = src_emb[word2id[word]]\n",
    "    scores = (tgt_emb / np.linalg.norm(tgt_emb, 2, 1)[:, None]).dot(word_emb / np.linalg.norm(word_emb))\n",
    "    k_best = scores.argsort()[-K:][::-1]\n",
    "    for i, idx in enumerate(k_best):\n",
    "        print('%.4f - %s' % (scores[idx], tgt_id2word[idx]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "src_word = 'кіт'\n",
    "get_nn(src_word, src_embeddings_uk, src_id2word_uk, src_embeddings_en, src_id2word_en, K=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.test.utils import common_corpus, common_dictionary, datapath\n",
    "from gensim import corpora\n",
    "from gensim.models import HdpModel, LdaMulticore, LdaModel\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "lda_uk = LdaModel.load(datapath('lda_uk'))\n",
    "lda_en = LdaModel.load(datapath('lda_en'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_topics(lda):\n",
    "    for i in range(lda.num_topics):\n",
    "        topic_terms = lda.get_topic_terms(topicid=i)\n",
    "        print(\"Topic \", i)\n",
    "        for term in topic_terms:\n",
    "            print(lda.id2word[term[0]], \" : \", term[1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_topics(lda_en)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.49274123949257986"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "word2id_uk = {v: k for k, v in src_id2word_uk.items()}\n",
    "vect1 = src_embeddings_uk[word2id_uk[\"кіт\"]]\n",
    "\n",
    "word2id_en = {v: k for k, v in src_id2word_en.items()}\n",
    "vect2 = src_embeddings_en[word2id_en[\"cat\"]]\n",
    "\n",
    "distance.cosine(vect1, vect2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "dict_uk = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "# corpus = [lda_uk.id2word.doc2bow(text) for text in lda_uk.]\n",
    "\n",
    "df = pd.read_json(f'preprocessed_dump_uk.json', orient='records')\n",
    "texts = df['text'].tolist()\n",
    "id2word = corpora.Dictionary(texts)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "cm = CoherenceModel(model=lda_uk, corpus=corpus, texts=texts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6576220335975637"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "cm.get_coherence()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9316e44d6a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "del texts, id2word, corpus\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "del df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5366094311625588"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "df = pd.read_json(f'preprocessed_dump_en.json', orient='records')\n",
    "texts = df['text'].tolist()\n",
    "id2word = corpora.Dictionary(texts)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "cm_en = CoherenceModel(model=lda_en, corpus=corpus, texts=texts)\n",
    "cm_en.get_coherence()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "del df, texts, id2word, corpus, cm_en"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cf798fc8e58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_uk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlda_uk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/pyLDAvis/gensim.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/pyLDAvis/gensim.py\u001b[0m in \u001b[0;36m_extract_data\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dists)\u001b[0m\n\u001b[1;32m     46\u001b[0m           \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m           \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m       \u001b[0mdoc_topic_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/thesis/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpElogtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mexpElogbetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpElogbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;31m# The optimal phi_{dwk} is proportional to expElogthetad_k * expElogbetad_w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1199135 is out of bounds for axis 1 with size 1199135"
     ],
     "ename": "IndexError",
     "evalue": "index 1199135 is out of bounds for axis 1 with size 1199135",
     "output_type": "error"
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "df = pd.read_json(f'preprocessed_dump_uk.json', orient='records')\n",
    "texts = df['text'].tolist()\n",
    "id2word = corpora.Dictionary(texts)\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_uk, corpus, dictionary=lda_uk.id2word)\n",
    "vis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "муніципалітет\nпровінція\nіталія\nсхід\nрегіон\nпримітка\nнаселення\nсписок\nзахід\nрозташований\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "word2id_uk = {v: k for k, v in src_id2word_uk.items()}\n",
    "i = 5\n",
    "pairs = lda_uk.get_topic_terms(i)\n",
    "for pair in pairs:\n",
    "    word = lda_uk.id2word[pair[0]]\n",
    "    print(word)\n",
    "    try:\n",
    "        emb = src_embeddings_uk[word2id_uk[word]]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "exceptions :  0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "count = 0\n",
    "word2id_en = {v: k for k, v in src_id2word_en.items()}\n",
    "for i in range(lda_en.num_topics):\n",
    "    pairs_en = lda_en.get_topic_terms(i)\n",
    "    for pair in pairs_en:\n",
    "        word = lda_en.id2word[pair[0]]\n",
    "        try:\n",
    "            emb = src_embeddings_en[word2id_en[word]]\n",
    "        except:\n",
    "            count += 1\n",
    "            continue\n",
    "print(\"exceptions : \", count)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[(3293, 0.08925211),\n (3467, 0.07377604),\n (4775, 0.0320496),\n (3587, 0.028706985),\n (1096, 0.028052008),\n (211, 0.025943672),\n (983, 0.025624007),\n (4009, 0.025449486),\n (3134, 0.024663284),\n (2612, 0.024061227)]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "i = 5\n",
    "terms = lda_uk.get_topic_terms(i)\n",
    "for term in terms:\n",
    "    word = lda_uk.id2word[term[0]]\n",
    "    probability = term[1]\n",
    "    try:\n",
    "        emb = src_embeddings_uk[word2id_uk[word]]\n",
    "    except:\n",
    "        continue\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def words_to_vectors(model, embeddings, src_id2word):\n",
    "    topics = dict()\n",
    "    word2id = {v: k for k, v in src_id2word.items()}\n",
    "    print(\"num of topics : \", model.num_topics)\n",
    "    for i in range(model.num_topics):\n",
    "        terms = model.get_topic_terms(i)\n",
    "        topic_terms = []\n",
    "        for term in terms:\n",
    "            word = model.id2word[term[0]]\n",
    "            probability = term[1]\n",
    "            try:\n",
    "                emb = embeddings[word2id[word]]\n",
    "                topic_terms.append([emb, probability])\n",
    "            except:\n",
    "                print(\"word not found\")\n",
    "        topics[i] = topic_terms\n",
    "    return topics\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "num of topics :  40\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "en_topics = words_to_vectors(lda_en, src_embeddings_en, src_id2word_en)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "40"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "len(en_topics)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "num of topics :  40\n",
      "word not found\n",
      "word not found\n",
      "word not found\nword not found\n",
      "word not found\nword not found\n",
      "word not found\n",
      "word not found\n",
      "word not found\nword not found\n",
      "word not found\nword not found\n",
      "word not found\n",
      "word not found\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "uk_topics = words_to_vectors(lda_uk, src_embeddings_uk, src_id2word_uk)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def topics_distance(topic1, topic2):\n",
    "    dist = 0\n",
    "    for i in range(len(topic1)):\n",
    "        dist = dist + distance.cosine(topic1[i][0], topic2[i][0])\n",
    "    return dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "min_idx = 0\n",
    "min_distance = 100\n",
    "for i in en_topics:\n",
    "   topic = en_topics[i]\n",
    "   dist = topics_distance(uk_topics[4], topic)\n",
    "   if dist < min_distance:\n",
    "       min_idx = i\n",
    "       min_distance = dist\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "8.419279278838296"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 82
    }
   ],
   "source": [
    "topics_distance(uk_topics[0], en_topics[0])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "37"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 84
    }
   ],
   "source": [
    "min_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "церква  :  0.010906376\nсвятий  :  0.006578559\nбог  :  0.004887131\nмонастир  :  0.004718315\nсвято  :  0.0045853527\nправославний  :  0.004357659\nхрам  :  0.004153548\nсобор  :  0.004079672\nєпископ  :  0.0035496019\nстоліття  :  0.0033643253\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "topic_terms = lda_uk.get_topic_terms(topicid=4)\n",
    "for term in topic_terms:\n",
    "    print(lda_uk.id2word[term[0]], \" : \", term[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "church  :  0.011229369\nchristian  :  0.005166045\njesus  :  0.004948357\ncentury  :  0.0049105994\nsaint  :  0.004751941\nchrist  :  0.0041244915\ntime  :  0.003266497\nroman  :  0.0032638793\nsay  :  0.0032421981\naccord  :  0.0030428693\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "topic_terms = lda_en.get_topic_terms(topicid=37)\n",
    "for term in topic_terms:\n",
    "    print(lda_en.id2word[term[0]], \" : \", term[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def find_closest_topic(topic, topics_list):\n",
    "    min_idx = 0\n",
    "    min_distance = 100\n",
    "    for i in topics_list:\n",
    "       t = topics_list[i]\n",
    "       dist = topics_distance(topic, t)\n",
    "       if dist < min_distance:\n",
    "           min_idx = i\n",
    "           min_distance = dist\n",
    "    return min_idx, min_distance\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def show_topic_terms(model, id):\n",
    "    topic_terms = model.get_topic_terms(topicid=id)\n",
    "    for term in topic_terms:\n",
    "        print(model.id2word[term[0]], \" : \", term[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "український  :  0.01090142\nармія  :  0.010775449\nвійсько  :  0.0104261385\nвійськовий  :  0.0097133\nрадянський  :  0.008174462\nросійський  :  0.00796036\nвійна  :  0.00766874\nполк  :  0.006906269\nукраїна  :  0.0061086034\nгенерал  :  0.004987835\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "show_topic_terms(lda_uk, 23)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "force  :  0.011041672\narmy  :  0.007784993\nmilitary  :  0.007615827\nstate  :  0.005951281\nbattle  :  0.005930984\nsoviet  :  0.005286651\ngovernment  :  0.004951337\nchina  :  0.0044536702\nbritish  :  0.004414635\nattack  :  0.00428505\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "uk_topic = uk_topics[23]\n",
    "min_idx, min_dist = find_closest_topic(uk_topic, en_topics)\n",
    "show_topic_terms(lda_en, min_idx)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "острів  :  0.013531725\nрічка  :  0.011641236\nозеро  :  0.010140168\nгора  :  0.009440495\nчастина  :  0.0094235875\nпівденний  :  0.008294909\nземля  :  0.007825516\nпівнічний  :  0.007621172\nвеликий  :  0.0065237707\nвисота  :  0.006252185\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "show_topic_terms(lda_uk, 25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "island  :  0.010343966\nwater  :  0.00896965\nislands  :  0.007887532\nnorth  :  0.0069999634\nsouth  :  0.0062251817\nland  :  0.005586973\nriver  :  0.0053218524\nspecies  :  0.0051699486\narea  :  0.004390231\ninclude  :  0.0043121492\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "uk_topic = uk_topics[25]\n",
    "min_idx, min_dist = find_closest_topic(uk_topic, en_topics)\n",
    "show_topic_terms(lda_en, min_idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}